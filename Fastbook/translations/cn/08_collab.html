<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>collab – Сергей Мирошниченко</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-c00b42e811b0fd9a18ac62455ba22490.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Сергей Мирошниченко</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../posts.html"> 
<span class="menu-text">Блог</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="第八章协同过滤深入探讨" class="level1">
<h1>第八章：协同过滤深入探讨</h1>
<p>解决的一个常见问题是有一定数量的用户和产品，您想推荐哪些产品最有可能对哪些用户有用。存在许多变体：例如，推荐电影（如 Netflix 上），确定在主页上为用户突出显示什么，决定在社交媒体动态中显示什么故事等。解决这个问题的一般方法称为<em>协同过滤</em>，工作原理如下：查看当前用户使用或喜欢的产品，找到其他使用或喜欢类似产品的用户，然后推荐那些用户使用或喜欢的其他产品。</p>
<p>例如，在 Netflix 上，您可能观看了很多科幻、充满动作并且是上世纪 70 年代制作的电影。Netflix 可能不知道您观看的这些电影的特定属性，但它将能够看到观看了与您观看相同电影的其他人也倾向于观看其他科幻、充满动作并且是上世纪 70 年代制作的电影。换句话说，要使用这种方法，我们不一定需要了解电影的任何信息，只需要知道谁喜欢观看它们。</p>
<p>这种方法可以解决更一般的一类问题，不一定涉及用户和产品。实际上，在协同过滤中，我们更常用<em>项目</em>这个术语，而不是<em>产品</em>。项目可以是人们点击的链接、为患者选择的诊断等。</p>
<p>关键的基础概念是<em>潜在因素</em>。在 Netflix 的例子中，我们假设您喜欢老式、充满动作的科幻电影。但您从未告诉 Netflix 您喜欢这类电影。Netflix 也不需要在其电影表中添加列，说明哪些电影属于这些类型。尽管如此，必须存在一些关于科幻、动作和电影年龄的潜在概念，这些概念对于至少一些人的电影观看决策是相关的。</p>
<p>在本章中，我们将解决这个电影推荐问题。我们将从获取适合协同过滤模型的一些数据开始。</p>
</section>
<section id="数据初探" class="level1">
<h1>数据初探</h1>
<p>我们无法访问 Netflix 的完整电影观看历史数据集，但有一个很好的数据集可供我们使用，称为<a href="https://oreil.ly/gP3Q5">MovieLens</a>。该数据集包含数千万部电影排名（电影 ID、用户 ID 和数字评分的组合），尽管我们只会使用其中的 10 万部作为示例。如果您感兴趣，可以尝试在完整的 2500 万推荐数据集上复制这种方法，您可以从他们的网站上获取。</p>
<p>该数据集可通过通常的 fastai 函数获得：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.collab <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.ML_100k)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>根据<em>README</em>，主表位于文件<em>u.data</em>中。它是以制表符分隔的，列分别是用户、电影、评分和时间戳。由于这些名称没有编码，我们需要在使用 Pandas 读取文件时指定它们。以下是打开此表并查看的方法：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>ratings <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'u.data'</span>, delimiter<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>, header<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>                      names<span class="op">=</span>[<span class="st">'user'</span>,<span class="st">'movie'</span>,<span class="st">'rating'</span>,<span class="st">'timestamp'</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>ratings.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>用户</th>
<th>电影</th>
<th>评分</th>
<th>时间戳</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>196</td>
<td>242</td>
<td>3</td>
<td>881250949</td>
</tr>
<tr class="even">
<td>1</td>
<td>186</td>
<td>302</td>
<td>3</td>
<td>891717742</td>
</tr>
<tr class="odd">
<td>2</td>
<td>22</td>
<td>377</td>
<td>1</td>
<td>878887116</td>
</tr>
<tr class="even">
<td>3</td>
<td>244</td>
<td>51</td>
<td>2</td>
<td>880606923</td>
</tr>
<tr class="odd">
<td>4</td>
<td>166</td>
<td>346</td>
<td>1</td>
<td>886397596</td>
</tr>
</tbody>
</table>
<p>尽管这包含了我们需要的所有信息，但这并不是人类查看这些数据的特别有用的方式。图 8-1 将相同数据交叉制表成了一个人类友好的表格。</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dlcf_0801.png" class="img-fluid figure-img"></p>
<figcaption>电影和用户的交叉表</figcaption>
</figure>
</div>
<section id="图-8-1.-电影和用户的交叉表" class="level6">
<h6 class="anchored" data-anchor-id="图-8-1.-电影和用户的交叉表">图 8-1. 电影和用户的交叉表</h6>
<p>我们只选择了一些最受欢迎的电影和观看电影最多的用户，作为这个交叉表示例。这个表格中的空单元格是我们希望我们的模型学会填充的内容。这些是用户尚未评论电影的地方，可能是因为他们还没有观看。对于每个用户，我们希望找出他们最有可能喜欢哪些电影。</p>
<p>如果我们知道每个用户对电影可能属于的每个重要类别的喜好程度，比如流派、年龄、喜欢的导演和演员等，以及我们对每部电影的相同信息，那么填写这个表格的一个简单方法是将这些信息相乘，然后使用组合。例如，假设这些因子的范围在-1 到+1 之间，正数表示更强的匹配，负数表示更弱的匹配，类别是科幻、动作和老电影，那么我们可以表示电影《最后的绝地武士》如下：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>last_skywalker <span class="op">=</span> np.array([<span class="fl">0.98</span>,<span class="fl">0.9</span>,<span class="op">-</span><span class="fl">0.9</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>在这里，例如，我们将<em>非常科幻</em>评分为 0.98，<em>非常不老</em>评分为-0.9。我们可以表示喜欢现代科幻动作电影的用户如下：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>user1 <span class="op">=</span> np.array([<span class="fl">0.9</span>,<span class="fl">0.8</span>,<span class="op">-</span><span class="fl">0.6</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>现在我们可以计算这种组合之间的匹配：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>(user1<span class="op">*</span>last_skywalker).<span class="bu">sum</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fl">2.1420000000000003</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>当我们将两个向量相乘并将结果相加时，这被称为<em>点积</em>。它在机器学习中被广泛使用，并构成了矩阵乘法的基础。我们将在第十七章中更多地研究矩阵乘法和点积。</p>
</section>
</section>
<section id="术语点积" class="level1">
<h1>术语：点积</h1>
<p>将两个向量的元素相乘，然后将结果相加的数学运算。</p>
<p>另一方面，我们可以表示电影《卡萨布兰卡》如下：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>casablanca <span class="op">=</span> np.array([<span class="op">-</span><span class="fl">0.99</span>,<span class="op">-</span><span class="fl">0.3</span>,<span class="fl">0.8</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>这种组合之间的匹配如下所示：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>(user1<span class="op">*</span>casablanca).<span class="bu">sum</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="fl">1.611</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>由于我们不知道潜在因子是什么，也不知道如何为每个用户和电影评分，我们应该学习它们。</p>
</section>
<section id="学习潜在因子" class="level1">
<h1>学习潜在因子</h1>
<p>在指定模型的结构和学习模型之间，实际上几乎没有什么区别，因为我们可以使用我们的一般梯度下降方法。</p>
<p>这种方法的第一步是随机初始化一些参数。这些参数将是每个用户和电影的一组潜在因子。我们将不得不决定要使用多少个。我们将很快讨论如何选择这些，但为了说明，让我们现在使用 5 个。因为每个用户将有一组这些因子，每部电影也将有一组这些因子，我们可以在交叉表中的用户和电影旁边显示这些随机初始化的值，然后我们可以填写这些组合的点积。例如，图 8-2 显示了在 Microsoft Excel 中的样子，顶部左侧的单元格公式显示为示例。</p>
<p>这种方法的第二步是计算我们的预测。正如我们讨论过的，我们可以通过简单地将每部电影与每个用户进行点积来实现这一点。例如，如果第一个潜在用户因子代表用户喜欢动作电影的程度，第一个潜在电影因子代表电影是否有很多动作，那么如果用户喜欢动作电影并且电影中有很多动作，或者用户不喜欢动作电影并且电影中没有任何动作，这两者的乘积将特别高。另一方面，如果存在不匹配（用户喜欢动作电影但电影不是动作片，或者用户不喜欢动作电影但电影是动作片），乘积将非常低。</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dlcf_0802.png" class="img-fluid figure-img"></p>
<figcaption>交叉表中的潜在因子</figcaption>
</figure>
</div>
<section id="图-8-2.-交叉表中的潜在因子" class="level6">
<h6 class="anchored" data-anchor-id="图-8-2.-交叉表中的潜在因子">图 8-2. 交叉表中的潜在因子</h6>
<p>第三步是计算我们的损失。我们可以使用任何损失函数，让我们现在选择均方误差，因为这是一种合理的表示预测准确性的方法。</p>
<p>这就是我们需要的全部内容。有了这个，我们可以使用随机梯度下降来优化我们的参数（潜在因素），以最小化损失。在每一步中，随机梯度下降优化器将使用点积计算每部电影与每个用户之间的匹配，并将其与每个用户给出的每部电影的实际评分进行比较。然后它将计算这个值的导数，并通过学习率乘以这个值来调整权重。经过多次这样的操作，损失会变得越来越好，推荐也会变得越来越好。</p>
<p>要使用通常的<code>Learner.fit</code>函数，我们需要将我们的数据放入<code>DataLoaders</code>中，所以让我们现在专注于这一点。</p>
</section>
</section>
<section id="创建-dataloaders" class="level1">
<h1>创建 DataLoaders</h1>
<p>在展示数据时，我们宁愿看到电影标题而不是它们的 ID。表<code>u.item</code>包含 ID 与标题的对应关系：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>movies <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'u.item'</span>,  delimiter<span class="op">=</span><span class="st">'|'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                     usecols<span class="op">=</span>(<span class="dv">0</span>,<span class="dv">1</span>), names<span class="op">=</span>(<span class="st">'movie'</span>,<span class="st">'title'</span>), header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>movies.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>电影</th>
<th>标题</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1</td>
<td>玩具总动员（1995）</td>
</tr>
<tr class="even">
<td>1</td>
<td>2</td>
<td>黄金眼（1995）</td>
</tr>
<tr class="odd">
<td>2</td>
<td>3</td>
<td>四个房间（1995）</td>
</tr>
<tr class="even">
<td>3</td>
<td>4</td>
<td>短小（1995）</td>
</tr>
<tr class="odd">
<td>4</td>
<td>5</td>
<td>复制猫（1995）</td>
</tr>
</tbody>
</table>
<p>我们可以将这个表与我们的<code>ratings</code>表合并，以获得按标题分类的用户评分：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>ratings <span class="op">=</span> ratings.merge(movies)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>ratings.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>用户</th>
<th>电影</th>
<th>评分</th>
<th>时间戳</th>
<th>标题</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>196</td>
<td>242</td>
<td>3</td>
<td>881250949</td>
<td>科洛亚（1996）</td>
</tr>
<tr class="even">
<td>1</td>
<td>63</td>
<td>242</td>
<td>3</td>
<td>875747190</td>
<td>科洛亚（1996）</td>
</tr>
<tr class="odd">
<td>2</td>
<td>226</td>
<td>242</td>
<td>5</td>
<td>883888671</td>
<td>科洛亚（1996）</td>
</tr>
<tr class="even">
<td>3</td>
<td>154</td>
<td>242</td>
<td>3</td>
<td>879138235</td>
<td>科洛亚（1996）</td>
</tr>
<tr class="odd">
<td>4</td>
<td>306</td>
<td>242</td>
<td>5</td>
<td>876503793</td>
<td>科洛亚（1996）</td>
</tr>
</tbody>
</table>
<p>然后我们可以从这个表构建一个<code>DataLoaders</code>对象。默认情况下，它将使用第一列作为用户，第二列作为项目（这里是我们的电影），第三列作为评分。在我们的情况下，我们需要更改<code>item_name</code>的值，以使用标题而不是 ID：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> CollabDataLoaders.from_df(ratings, item_name<span class="op">=</span><span class="st">'title'</span>, bs<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>用户</th>
<th>标题</th>
<th>评分</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>207</td>
<td>四个婚礼和一个葬礼（1994）</td>
<td>3</td>
</tr>
<tr class="even">
<td>1</td>
<td>565</td>
<td>日残余（1993）</td>
<td>5</td>
</tr>
<tr class="odd">
<td>2</td>
<td>506</td>
<td>小孩（1995）</td>
<td>1</td>
</tr>
<tr class="even">
<td>3</td>
<td>845</td>
<td>追求艾米（1997）</td>
<td>3</td>
</tr>
<tr class="odd">
<td>4</td>
<td>798</td>
<td>人类（1993）</td>
<td>2</td>
</tr>
<tr class="even">
<td>5</td>
<td>500</td>
<td>低俗法则（1986）</td>
<td>4</td>
</tr>
<tr class="odd">
<td>6</td>
<td>409</td>
<td>无事生非（1993）</td>
<td>3</td>
</tr>
<tr class="even">
<td>7</td>
<td>721</td>
<td>勇敢的心（1995）</td>
<td>5</td>
</tr>
<tr class="odd">
<td>8</td>
<td>316</td>
<td>精神病患者（1960）</td>
<td>2</td>
</tr>
<tr class="even">
<td>9</td>
<td>883</td>
<td>判决之夜（1993）</td>
<td>5</td>
</tr>
</tbody>
</table>
<p>为了在 PyTorch 中表示协同过滤，我们不能直接使用交叉表表示，特别是如果我们希望它适应我们的深度学习框架。我们可以将我们的电影和用户潜在因素表表示为简单的矩阵：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>n_users  <span class="op">=</span> <span class="bu">len</span>(dls.classes[<span class="st">'user'</span>])</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>n_movies <span class="op">=</span> <span class="bu">len</span>(dls.classes[<span class="st">'title'</span>])</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>n_factors <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>user_factors <span class="op">=</span> torch.randn(n_users, n_factors)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>movie_factors <span class="op">=</span> torch.randn(n_movies, n_factors)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>要计算特定电影和用户组合的结果，我们必须查找电影在我们的电影潜在因素矩阵中的索引，以及用户在我们的用户潜在因素矩阵中的索引；然后我们可以在两个潜在因素向量之间进行点积。但<em>查找索引</em>不是我们的深度学习模型知道如何执行的操作。它们知道如何执行矩阵乘积和激活函数。</p>
<p>幸运的是，我们可以将<em>查找索引</em>表示为矩阵乘积。技巧是用单热编码向量替换我们的索引。这是一个例子，展示了如果我们将一个向量乘以一个表示索引 3 的单热编码向量会发生什么：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>one_hot_3 <span class="op">=</span> one_hot(<span class="dv">3</span>, n_users).<span class="bu">float</span>()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>user_factors.t() <span class="op">@</span> one_hot_3</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="op">-</span><span class="fl">0.4586</span>, <span class="op">-</span><span class="fl">0.9915</span>, <span class="op">-</span><span class="fl">0.4052</span>, <span class="op">-</span><span class="fl">0.3621</span>, <span class="op">-</span><span class="fl">0.5908</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>它给我们的结果与矩阵中索引 3 处的向量相同：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>user_factors[<span class="dv">3</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="op">-</span><span class="fl">0.4586</span>, <span class="op">-</span><span class="fl">0.9915</span>, <span class="op">-</span><span class="fl">0.4052</span>, <span class="op">-</span><span class="fl">0.3621</span>, <span class="op">-</span><span class="fl">0.5908</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>如果我们一次为几个索引这样做，我们将得到一个独热编码向量的矩阵，这个操作将是一个矩阵乘法！这将是使用这种架构构建模型的一种完全可接受的方式，只是它会比必要的使用更多的内存和时间。我们知道没有真正的基础原因来存储独热编码向量，或者通过搜索找到数字 1 的出现 - 我们应该能够直接使用整数索引到数组中。因此，大多数深度学习库，包括 PyTorch，都包括一个特殊的层，它就是这样做的；它使用整数索引到一个向量中，但其导数的计算方式使其与使用独热编码向量进行矩阵乘法时完全相同。这被称为<em>嵌入</em>。</p>
</section>
<section id="术语嵌入" class="level1">
<h1>术语：嵌入</h1>
<p>通过一个独热编码矩阵相乘，使用计算快捷方式，可以通过直接索引来实现。这是一个非常简单概念的相当花哨的词。您将独热编码矩阵相乘的东西（或者使用计算快捷方式，直接索引）称为<em>嵌入矩阵</em>。</p>
<p>在计算机视觉中，我们有一种非常简单的方法通过其 RGB 值获取像素的所有信息：彩色图像中的每个像素由三个数字表示。这三个数字给我们红色、绿色和蓝色，这足以让我们的模型在之后工作。</p>
<p>对于手头的问题，我们没有同样简单的方法来描述用户或电影。可能与流派有关：如果给定用户喜欢爱情片，他们可能会给爱情片更高的评分。其他因素可能是电影是更注重动作还是对话，或者是否有一个特定的演员，用户可能特别喜欢。</p>
<p>我们如何确定用来描述这些数字的数字？答案是，我们不确定。我们将让我们的模型<em>学习</em>它们。通过分析用户和电影之间的现有关系，我们的模型可以自己找出看起来重要或不重要的特征。</p>
<p>这就是嵌入。我们将为我们的每个用户和每个电影分配一个特定长度的随机向量（这里，<code>n_factors=5</code>），并将使它们成为可学习的参数。这意味着在每一步，当我们通过比较我们的预测和目标来计算损失时，我们将计算损失相对于这些嵌入向量的梯度，并根据 SGD（或其他优化器）的规则更新它们。</p>
<p>一开始，这些数字没有任何意义，因为我们是随机选择的，但在训练结束时，它们将有意义。通过学习关于用户和电影之间关系的现有数据，没有任何其他信息，我们将看到它们仍然获得一些重要特征，并且可以将大片与独立电影、动作片与爱情片等区分开来。</p>
<p>我们现在有能力从头开始创建我们的整个模型。</p>
</section>
<section id="从头开始协同过滤" class="level1">
<h1>从头开始协同过滤</h1>
<p>在我们可以用 PyTorch 编写模型之前，我们首先需要学习面向对象编程和 Python 的基础知识。如果您以前没有进行过面向对象编程，我们将在这里为您进行快速介绍，但我们建议您在继续之前查阅教程并进行一些练习。</p>
<p>面向对象编程中的关键思想是<em>类</em>。我们在本书中一直在使用类，比如<code>DataLoader</code>、<code>String</code>和<code>Learner</code>。Python 还让我们很容易地创建新类。这是一个简单类的示例：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Example:</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, a): <span class="va">self</span>.a <span class="op">=</span> a</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> say(<span class="va">self</span>,x): <span class="cf">return</span> <span class="ss">f'Hello </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>a<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">.'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>这其中最重要的部分是一个特殊的方法叫做<code>__init__</code>（发音为<em>dunder init</em>）。在 Python 中，任何像这样用双下划线包围的方法都被认为是特殊的。它表示与这个方法名称相关联一些额外的行为。对于<code>__init__</code>，这是 Python 在创建新对象时将调用的方法。因此，这是你可以在对象创建时设置任何需要初始化的状态的地方。当用户构造类的实例时包含的任何参数都将作为参数传递给<code>__init__</code>方法。请注意，在类内定义的任何方法的第一个参数是<code>self</code>，因此你可以使用它来设置和获取任何你需要的属性：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb19"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>ex <span class="op">=</span> Example(<span class="st">'Sylvain'</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>ex.say(<span class="st">'nice to meet you'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">'Hello Sylvain, nice to meet you.'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>还要注意，创建一个新的 PyTorch 模块需要继承自<code>Module</code>。<em>继承</em>是一个重要的面向对象的概念，在这里我们不会详细讨论——简而言之，它意味着我们可以向现有类添加额外的行为。PyTorch 已经提供了一个<code>Module</code>类，它提供了一些我们想要构建的基本基础。因此，我们在定义类的名称后面添加这个<em>超类</em>的名称，如下面的示例所示。</p>
<p>你需要知道创建一个新的 PyTorch 模块的最后一件事是，当调用你的模块时，PyTorch 将调用你的类中的一个名为<code>forward</code>的方法，并将包含在调用中的任何参数传递给它。这是定义我们的点积模型的类：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProduct(Module):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(n_users, n_factors)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> Embedding(n_movies, n_factors)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors(x[:,<span class="dv">0</span>])</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors(x[:,<span class="dv">1</span>])</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>如果你以前没有见过面向对象的编程，不用担心；在这本书中你不需要经常使用它。我们在这里提到这种方法只是因为大多数在线教程和文档将使用面向对象的语法。</p>
<p>请注意，模型的输入是一个形状为<code>batch_size x 2</code>的张量，其中第一列（<code>x[:, 0]</code>）包含用户 ID，第二列（<code>x[:, 1]</code>）包含电影 ID。如前所述，我们使用<em>嵌入</em>层来表示我们的用户和电影潜在因子的矩阵：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>x,y <span class="op">=</span> dls.one_batch()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>torch.Size([<span class="dv">64</span>, <span class="dv">2</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>现在我们已经定义了我们的架构并创建了参数矩阵，我们需要创建一个<code>Learner</code>来优化我们的模型。在过去，我们使用了特殊函数，比如<code>cnn_learner</code>，为特定应用程序为我们设置了一切。由于我们在这里从头开始做事情，我们将使用普通的<code>Learner</code>类：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb24"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProduct(n_users, n_movies, <span class="dv">50</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>现在我们准备拟合我们的模型：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.326261</td>
<td>1.295701</td>
<td>00:12</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.091352</td>
<td>1.091475</td>
<td>00:11</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.961574</td>
<td>0.977690</td>
<td>00:11</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.829995</td>
<td>0.893122</td>
<td>00:11</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.781661</td>
<td>0.876511</td>
<td>00:12</td>
</tr>
</tbody>
</table>
<p>我们可以做的第一件事是让这个模型更好一点，强制这些预测值在 0 到 5 之间。为此，我们只需要使用<code>sigmoid_range</code>，就像第六章中那样。我们经验性地发现，最好让范围略微超过 5，所以我们使用<code>(0, 5.5)</code>：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProduct(Module):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(n_users, n_factors)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> Embedding(n_movies, n_factors)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors(x[:,<span class="dv">0</span>])</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors(x[:,<span class="dv">1</span>])</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range((users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>), <span class="op">*</span><span class="va">self</span>.y_range)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProduct(n_users, n_movies, <span class="dv">50</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.976380</td>
<td>1.001455</td>
<td>00:12</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.875964</td>
<td>0.919960</td>
<td>00:12</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.685377</td>
<td>0.870664</td>
<td>00:12</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.483701</td>
<td>0.874071</td>
<td>00:12</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.385249</td>
<td>0.878055</td>
<td>00:12</td>
</tr>
</tbody>
</table>
<p>这是一个合理的开始，但我们可以做得更好。一个明显缺失的部分是，有些用户在推荐中只是更积极或更消极，有些电影只是比其他电影更好或更差。但在我们的点积表示中，我们没有任何方法来编码这两件事。如果你只能说一部电影，例如，它非常科幻，非常动作导向，非常不老旧，那么你实际上没有办法说大多数人是否喜欢它。</p>
<p>这是因为在这一点上我们只有权重；我们没有偏差。如果我们为每个用户有一个可以添加到我们的分数中的单个数字，对于每部电影也是如此，那么这将非常好地处理这个缺失的部分。因此，首先让我们调整我们的模型架构：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProductBias(Module):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(n_users, n_factors)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_bias <span class="op">=</span> Embedding(n_users, <span class="dv">1</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> Embedding(n_movies, n_factors)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_bias <span class="op">=</span> Embedding(n_movies, <span class="dv">1</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors(x[:,<span class="dv">0</span>])</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors(x[:,<span class="dv">1</span>])</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> (users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        res <span class="op">+=</span> <span class="va">self</span>.user_bias(x[:,<span class="dv">0</span>]) <span class="op">+</span> <span class="va">self</span>.movie_bias(x[:,<span class="dv">1</span>])</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(res, <span class="op">*</span><span class="va">self</span>.y_range)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>让我们尝试训练这个模型，看看效果如何：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBias(n_users, n_movies, <span class="dv">50</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.929161</td>
<td>0.936303</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.820444</td>
<td>0.861306</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.621612</td>
<td>0.865306</td>
<td>00:14</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.404648</td>
<td>0.886448</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.292948</td>
<td>0.892580</td>
<td>00:13</td>
</tr>
</tbody>
</table>
<p>但是，结果并不比之前更好（至少在训练结束时）。为什么呢？如果我们仔细观察这两次训练，我们会发现验证损失在中间停止改善并开始变差。正如我们所见，这是过拟合的明显迹象。在这种情况下，没有办法使用数据增强，所以我们将不得不使用另一种正则化技术。一个有帮助的方法是<em>权重衰减</em>。</p>
<section id="weight-decay" class="level2">
<h2 class="anchored" data-anchor-id="weight-decay">Weight Decay</h2>
<p>权重衰减，或<em>L2 正则化</em>，包括将所有权重的平方和添加到损失函数中。为什么这样做？因为当我们计算梯度时，它会为梯度增加一个贡献，鼓励权重尽可能小。</p>
<p>为什么它可以防止过拟合？这个想法是，系数越大，损失函数中的峡谷就会越尖锐。如果我们以抛物线的基本例子<code>y = a * (x**2)</code>为例，<code>a</code>越大，抛物线就越<em>狭窄</em>：</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dlcf_0803.png" class="img-fluid figure-img"></p>
<figcaption>不同 a 值的抛物线</figcaption>
</figure>
</div>
<p>因此，让我们的模型学习高参数可能导致它用一个过于复杂、具有非常尖锐变化的函数拟合训练集中的所有数据点，这将导致过拟合。</p>
<p>限制我们的权重过大会阻碍模型的训练，但会产生一个更好泛化的状态。回顾一下理论，权重衰减（或<code>wd</code>）是一个控制我们在损失中添加的平方和的参数（假设<code>parameters</code>是所有参数的张量）：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb30"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>loss_with_wd <span class="op">=</span> loss <span class="op">+</span> wd <span class="op">*</span> (parameters<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>然而，在实践中，计算那个大和并将其添加到损失中将非常低效（也许在数值上不稳定）。如果你还记得一点高中数学，你可能会记得<code>p**2</code>关于<code>p</code>的导数是<code>2*p</code>，所以将那个大和添加到我们的损失中，实际上等同于这样做：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb31"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>parameters.grad <span class="op">+=</span> wd <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> parameters</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>实际上，由于<code>wd</code>是我们选择的一个参数，我们可以使它变为两倍大，所以在这个方程中我们甚至不需要<code>*2</code>。要在 fastai 中使用权重衰减，在调用<code>fit</code>或<code>fit_one_cycle</code>时传递<code>wd</code>即可（可以同时传递）：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBias(n_users, n_movies, <span class="dv">50</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>, wd<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.972090</td>
<td>0.962366</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.875591</td>
<td>0.885106</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.723798</td>
<td>0.839880</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.586002</td>
<td>0.823225</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.490980</td>
<td>0.823060</td>
<td>00:13</td>
</tr>
</tbody>
</table>
<p>好多了！</p>
</section>
<section id="创建我们自己的嵌入模块" class="level2">
<h2 class="anchored" data-anchor-id="创建我们自己的嵌入模块">创建我们自己的嵌入模块</h2>
<p>到目前为止，我们使用<code>Embedding</code>而没有考虑它是如何工作的。让我们重新创建<code>DotProductBias</code>，<em>不</em>使用这个类。我们需要为每个嵌入初始化一个随机权重矩阵。然而，我们必须小心。回想一下第四章中提到的，优化器要求能够从模块的<code>parameters</code>方法中获取模块的所有参数。然而，这并不是完全自动发生的。如果我们只是将一个张量作为<code>Module</code>的属性添加，它不会包含在<code>parameters</code>中：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> T(Module):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): <span class="va">self</span>.a <span class="op">=</span> torch.ones(<span class="dv">3</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>L(T().parameters())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>(<span class="co">#0) []</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>要告诉<code>Module</code>我们希望将一个张量视为参数，我们必须将其包装在<code>nn.Parameter</code>类中。这个类不添加任何功能（除了自动为我们调用<code>requires_grad_</code>）。它只用作一个“标记”，以显示要包含在<code>parameters</code>中的内容：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb35"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> T(Module):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): <span class="va">self</span>.a <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">3</span>))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>L(T().parameters())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb36"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>(<span class="co">#1) [Parameter containing:</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>tensor([<span class="fl">1.</span>, <span class="fl">1.</span>, <span class="fl">1.</span>], requires_grad<span class="op">=</span><span class="va">True</span>)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>所有 PyTorch 模块都使用<code>nn.Parameter</code>来表示任何可训练参数，这就是为什么我们直到现在都不需要显式使用这个包装器：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb37"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> T(Module):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): <span class="va">self</span>.a <span class="op">=</span> nn.Linear(<span class="dv">1</span>, <span class="dv">3</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> T()</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>L(t.parameters())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>(<span class="co">#1) [Parameter containing:</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>tensor([[<span class="op">-</span><span class="fl">0.9595</span>],</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>        [<span class="op">-</span><span class="fl">0.8490</span>],</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>        [ <span class="fl">0.8159</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(t.a.weight)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>torch.nn.parameter.Parameter</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>我们可以创建一个张量作为参数，进行随机初始化，如下所示：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb41"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_params(size):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn.Parameter(torch.zeros(<span class="op">*</span>size).normal_(<span class="dv">0</span>, <span class="fl">0.01</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>让我们再次使用这个来创建<code>DotProductBias</code>，但不使用<code>Embedding</code>：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProductBias(Module):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> create_params([n_users, n_factors])</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_bias <span class="op">=</span> create_params([n_users])</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> create_params([n_movies, n_factors])</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_bias <span class="op">=</span> create_params([n_movies])</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors[x[:,<span class="dv">0</span>]]</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors[x[:,<span class="dv">1</span>]]</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> (users<span class="op">*</span>movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>        res <span class="op">+=</span> <span class="va">self</span>.user_bias[x[:,<span class="dv">0</span>]] <span class="op">+</span> <span class="va">self</span>.movie_bias[x[:,<span class="dv">1</span>]]</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(res, <span class="op">*</span><span class="va">self</span>.y_range)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>然后让我们再次训练它，以检查我们是否得到了与前一节中看到的大致相同的结果：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb43"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBias(n_users, n_movies, <span class="dv">50</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>, wd<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.962146</td>
<td>0.936952</td>
<td>00:14</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.858084</td>
<td>0.884951</td>
<td>00:14</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.740883</td>
<td>0.838549</td>
<td>00:14</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.592497</td>
<td>0.823599</td>
<td>00:14</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.473570</td>
<td>0.824263</td>
<td>00:14</td>
</tr>
</tbody>
</table>
<p>现在，让我们看看我们的模型学到了什么。</p>
</section>
</section>
<section id="解释嵌入和偏差" class="level1">
<h1>解释嵌入和偏差</h1>
<p>我们的模型已经很有用，因为它可以为我们的用户提供电影推荐，但看到它发现了什么参数也很有趣。最容易解释的是偏差。以下是偏差向量中值最低的电影：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>movie_bias <span class="op">=</span> learn.model.movie_bias.squeeze()</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort()[:<span class="dv">5</span>]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>[<span class="st">'Children of the Corn: The Gathering (1996)'</span>,</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a> <span class="st">'Lawnmower Man 2: Beyond Cyberspace (1996)'</span>,</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a> <span class="st">'Beautician and the Beast, The (1997)'</span>,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a> <span class="st">'Crow: City of Angels, The (1996)'</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a> <span class="st">'Home Alone 3 (1997)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>想想这意味着什么。它表明对于这些电影中的每一部，即使用户与其潜在因素非常匹配（稍后我们将看到，这些因素往往代表动作水平、电影年龄等等），他们通常仍然不喜欢它。我们本可以简单地按照电影的平均评分对其进行排序，但查看学到的偏差告诉我们更有趣的事情。它告诉我们不仅仅是电影是人们不喜欢观看的类型，而且即使是他们本来会喜欢的类型，人们也倾向于不喜欢观看！同样地，以下是偏差最高的电影：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb46"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort(descending<span class="op">=</span><span class="va">True</span>)[:<span class="dv">5</span>]</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb47"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>[<span class="st">'L.A. Confidential (1997)'</span>,</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a> <span class="st">'Titanic (1997)'</span>,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a> <span class="st">'Silence of the Lambs, The (1991)'</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a> <span class="st">'Shawshank Redemption, The (1994)'</span>,</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a> <span class="st">'Star Wars (1977)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>因此，例如，即使您通常不喜欢侦探电影，您可能会喜欢<em>LA 机密</em>！</p>
<p>直接解释嵌入矩阵并不那么容易。对于人类来说，因素太多了。但有一种技术可以提取出这种矩阵中最重要的基础<em>方向</em>，称为<em>主成分分析</em>（PCA）。我们不会在本书中详细讨论这个，因为您要成为深度学习从业者并不特别重要，但如果您感兴趣，我们建议您查看 fast.ai 课程<a href="https://oreil.ly/NLj2R">面向程序员的计算线性代数</a>。图 8-3 显示了基于两个最强的 PCA 组件的电影的外观。</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dlcf_0804.png" class="img-fluid figure-img"></p>
<figcaption>基于两个最强的 PCA 组件的电影表示</figcaption>
</figure>
</div>
<section id="图-8-3.-基于两个最强的-pca-组件的电影表示" class="level6">
<h6 class="anchored" data-anchor-id="图-8-3.-基于两个最强的-pca-组件的电影表示">图 8-3. 基于两个最强的 PCA 组件的电影表示</h6>
<p>我们可以看到模型似乎已经发现了<em>经典</em>与<em>流行文化</em>电影的概念，或者这里代表的是<em>广受好评</em>。</p>
</section>
</section>
<section id="杰里米说" class="level1">
<h1>杰里米说</h1>
<p>无论我训练多少模型，我永远不会停止被这些随机初始化的数字组合所感动和惊讶，这些数字通过如此简单的机制训练，竟然能够自己发现关于我的数据的东西。我几乎觉得可以欺骗，我可以创建一个能够做有用事情的代码，而从未真正告诉它如何做这些事情！</p>
<p>我们从头开始定义了我们的模型，以教给您内部情况，但您可以直接使用 fastai 库来构建它。我们将在下一节看看如何做到这一点。</p>
<section id="使用-fastai.collab" class="level2">
<h2 class="anchored" data-anchor-id="使用-fastai.collab">使用 fastai.collab</h2>
<p>我们可以使用 fastai 的<code>collab_learner</code>使用先前显示的确切结构创建和训练协同过滤模型：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb48"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> collab_learner(dls, n_factors<span class="op">=</span><span class="dv">50</span>, y_range<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">5.5</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb49"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>, wd<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.931751</td>
<td>0.953806</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.851826</td>
<td>0.878119</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.715254</td>
<td>0.834711</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.583173</td>
<td>0.821470</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.496625</td>
<td>0.821688</td>
<td>00:13</td>
</tr>
</tbody>
</table>
<p>通过打印模型可以看到层的名称：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb50"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>learn.model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>EmbeddingDotBias(</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  (u_weight): Embedding(<span class="dv">944</span>, <span class="dv">50</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  (i_weight): Embedding(<span class="dv">1635</span>, <span class="dv">50</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>  (u_bias): Embedding(<span class="dv">944</span>, <span class="dv">1</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  (i_bias): Embedding(<span class="dv">1635</span>, <span class="dv">1</span>)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>我们可以使用这些来复制我们在上一节中所做的任何分析，例如：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb52"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>movie_bias <span class="op">=</span> learn.model.i_bias.weight.squeeze()</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort(descending<span class="op">=</span><span class="va">True</span>)[:<span class="dv">5</span>]</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>[<span class="st">'Titanic (1997)'</span>,</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a> <span class="st">"Schindler's List (1993)"</span>,</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a> <span class="st">'Shawshank Redemption, The (1994)'</span>,</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a> <span class="st">'L.A. Confidential (1997)'</span>,</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a> <span class="st">'Silence of the Lambs, The (1991)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>我们可以使用这些学到的嵌入来查看<em>距离</em>。</p>
</section>
<section id="嵌入距离" class="level2">
<h2 class="anchored" data-anchor-id="嵌入距离">嵌入距离</h2>
<p>在二维地图上，我们可以通过使用毕达哥拉斯定理的公式来计算两个坐标之间的距离：<math alttext="StartRoot x squared plus y squared EndRoot"><msqrt><mrow><msup><mi>x</mi> <mn>2</mn></msup> <mo>+</mo> <msup><mi>y</mi> <mn>2</mn></msup></mrow></msqrt></math>（假设<em>x</em>和<em>y</em>是每个轴上坐标之间的距离）。对于一个 50 维的嵌入，我们可以做完全相同的事情，只是将所有 50 个坐标距离的平方相加。</p>
<p>如果有两部几乎相同的电影，它们的嵌入向量也必须几乎相同，因为喜欢它们的用户几乎完全相同。这里有一个更一般的想法：电影的相似性可以由喜欢这些电影的用户的相似性来定义。这直接意味着两部电影的嵌入向量之间的距离可以定义这种相似性。我们可以利用这一点找到与“沉默的羔羊”最相似的电影：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb54"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>movie_factors <span class="op">=</span> learn.model.i_weight.weight</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> dls.classes[<span class="st">'title'</span>].o2i[<span class="st">'Silence of the Lambs, The (1991)'</span>]</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> nn.CosineSimilarity(dim<span class="op">=</span><span class="dv">1</span>)(movie_factors, movie_factors[idx][<span class="va">None</span>])</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> distances.argsort(descending<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>dls.classes[<span class="st">'title'</span>][idx]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb55"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">'Dial M for Murder (1954)'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>现在我们已经成功训练了一个模型，让我们看看如何处理没有用户数据的情况。我们如何向新用户推荐？</p>
</section>
</section>
<section id="引导协同过滤模型" class="level1">
<h1>引导协同过滤模型</h1>
<p>在实践中使用协同过滤模型的最大挑战是“引导问题”。这个问题的最极端版本是没有用户，因此没有历史可供学习。您向您的第一个用户推荐什么产品？</p>
<p>但即使您是一家历史悠久的公司，拥有长期的用户交易记录，您仍然会面临一个问题：当新用户注册时，您该怎么办？实际上，当您向您的产品组合添加新产品时，您该怎么办？这个问题没有魔法解决方案，而我们建议的解决方案实际上只是“运用常识”的变体。您可以将新用户分配为其他用户所有嵌入向量的平均值，但这会带来一个问题，即该潜在因素的特定组合可能并不常见（例如，科幻因素的平均值可能很高，而动作因素的平均值可能很低，但很少有人喜欢科幻而不喜欢动作）。最好选择一个特定用户来代表“平均品味”。</p>
<p>更好的方法是使用基于用户元数据的表格模型来构建您的初始嵌入向量。当用户注册时，考虑一下您可以询问哪些问题来帮助您了解他们的口味。然后，您可以创建一个模型，其中因变量是用户的嵌入向量，而自变量是您问他们的问题的结果，以及他们的注册元数据。我们将在下一节中看到如何创建这些类型的表格模型。（您可能已经注意到，当您注册 Pandora 和 Netflix 等服务时，它们往往会问您一些关于您喜欢的电影或音乐类型的问题；这就是它们如何提出您的初始协同过滤推荐的方式。）</p>
<p>需要注意的一点是，一小部分非常热情的用户可能最终会有效地为整个用户群设置推荐。这是一个非常常见的问题，例如，在电影推荐系统中。看动漫的人往往会看很多动漫，而且不怎么看其他东西，花很多时间在网站上评分。因此，动漫往往在许多“有史以来最佳电影”列表中被过度代表。在这种特殊情况下，很明显您有一个代表性偏见的问题，但如果偏见发生在潜在因素中，可能一点也不明显。</p>
<p>这样的问题可能会改变您的用户群体的整体构成，以及您系统的行为。这特别是由于正反馈循环。如果您的一小部分用户倾向于设定您的推荐系统的方向，他们自然会吸引更多类似他们的人来到您的系统。这当然会放大原始的表征偏见。这种偏见是一种被指数级放大的自然倾向。您可能已经看到一些公司高管对他们的在线平台如何迅速恶化表示惊讶，以至于表达了与创始人价值观不符的价值观。在存在这种类型的反馈循环的情况下，很容易看到这种分歧如何迅速发生，以及以一种隐藏的方式，直到为时已晚。</p>
<p>在这样一个自我强化的系统中，我们可能应该预期这些反馈循环是常态，而不是例外。因此，您应该假设您会看到它们，为此做好计划，并提前确定如何处理这些问题。尝试考虑反馈循环可能在您的系统中表示的所有方式，以及您如何能够在数据中识别它们。最终，这又回到了我们关于如何在推出任何类型的机器学习系统时避免灾难的最初建议。这一切都是为了确保有人参与其中；有仔细的监控，以及一个渐进和周到的推出。</p>
<p>我们的点积模型效果相当不错，并且是许多成功的现实世界推荐系统的基础。这种协同过滤方法被称为<em>概率矩阵分解</em>（PMF）。另一种方法，通常在给定相同数据时效果类似，是深度学习。</p>
</section>
<section id="协同过滤的深度学习" class="level1">
<h1>协同过滤的深度学习</h1>
<p>将我们的架构转换为深度学习模型的第一步是获取嵌入查找的结果并将这些激活连接在一起。这给我们一个矩阵，然后我们可以按照通常的方式通过线性层和非线性传递它们。</p>
<p>由于我们将连接嵌入矩阵，而不是取它们的点积，所以两个嵌入矩阵可以具有不同的大小（不同数量的潜在因素）。fastai 有一个函数<code>get_emb_sz</code>，根据 fast.ai 发现在实践中往往效果良好的启发式方法，返回推荐的嵌入矩阵大小：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb56"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>embs <span class="op">=</span> get_emb_sz(dls)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>embs</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb57"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>[(<span class="dv">944</span>, <span class="dv">74</span>), (<span class="dv">1635</span>, <span class="dv">101</span>)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>让我们实现这个类：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb58"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CollabNN(Module):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, user_sz, item_sz, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>), n_act<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(<span class="op">*</span>user_sz)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.item_factors <span class="op">=</span> Embedding(<span class="op">*</span>item_sz)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.Sequential(</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(user_sz[<span class="dv">1</span>]<span class="op">+</span>item_sz[<span class="dv">1</span>], n_act),</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(n_act, <span class="dv">1</span>))</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>        embs <span class="op">=</span> <span class="va">self</span>.user_factors(x[:,<span class="dv">0</span>]),<span class="va">self</span>.item_factors(x[:,<span class="dv">1</span>])</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layers(torch.cat(embs, dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(x, <span class="op">*</span><span class="va">self</span>.y_range)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>并使用它创建一个模型：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb59"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CollabNN(<span class="op">*</span>embs)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><code>CollabNN</code>以与本章中先前类似的方式创建我们的<code>Embedding</code>层，只是现在我们使用<code>embs</code>大小。<code>self.layers</code>与我们在第四章为 MNIST 创建的迷你神经网络是相同的。然后，在<code>forward</code>中，我们应用嵌入，连接结果，并通过迷你神经网络传递。最后，我们像以前的模型一样应用<code>sigmoid_range</code>。</p>
<p>让我们看看它是否训练：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb60"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>, wd<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.940104</td>
<td>0.959786</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.893943</td>
<td>0.905222</td>
<td>00:14</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.865591</td>
<td>0.875238</td>
<td>00:14</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.800177</td>
<td>0.867468</td>
<td>00:14</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.760255</td>
<td>0.867455</td>
<td>00:14</td>
</tr>
</tbody>
</table>
<p>如果您在调用<code>collab_learner</code>时传递<code>use_nn=True</code>（包括为您调用<code>get_emb_sz</code>），fastai 在<code>fastai.collab</code>中提供了这个模型，并且让您轻松创建更多层。例如，在这里我们创建了两个隐藏层，分别为大小 100 和 50：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb61"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> collab_learner(dls, use_nn<span class="op">=</span><span class="va">True</span>, y_range<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">5.5</span>), layers<span class="op">=</span>[<span class="dv">100</span>,<span class="dv">50</span>])</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">5e-3</span>, wd<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>epoch</th>
<th>train_loss</th>
<th>valid_loss</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.002747</td>
<td>0.972392</td>
<td>00:16</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.926903</td>
<td>0.922348</td>
<td>00:16</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.877160</td>
<td>0.893401</td>
<td>00:16</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.838334</td>
<td>0.865040</td>
<td>00:16</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.781666</td>
<td>0.864936</td>
<td>00:16</td>
</tr>
</tbody>
</table>
<p><code>learn.model</code>是<code>EmbeddingNN</code>类型的对象。让我们看一下 fastai 对这个类的代码：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb62"><pre class="sourceCode py code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="at">@delegates</span>(TabularModel)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EmbeddingNN(TabularModel):</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, emb_szs, layers, <span class="op">**</span>kwargs):</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(emb_szs, layers<span class="op">=</span>layers, n_cont<span class="op">=</span><span class="dv">0</span>, out_sz<span class="op">=</span><span class="dv">1</span>, <span class="op">**</span>kwargs)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>哇，这不是很多代码！这个类<em>继承</em>自<code>TabularModel</code>，这是它获取所有功能的地方。在<code>__init__</code>中，它调用<code>TabularModel</code>中的相同方法，传递<code>n_cont=0</code>和<code>out_sz=1</code>；除此之外，它只传递它收到的任何参数。</p>
<p>尽管<code>EmbeddingNN</code>的结果比点积方法稍差一些（这显示了为领域精心构建架构的力量），但它确实允许我们做一件非常重要的事情：我们现在可以直接将其他用户和电影信息、日期和时间信息或任何可能与推荐相关的信息纳入考虑。这正是<code>TabularModel</code>所做的。事实上，我们现在已经看到，<code>EmbeddingNN</code>只是一个<code>TabularModel</code>，其中<code>n_cont=0</code>和<code>out_sz=1</code>。因此，我们最好花一些时间了解<code>TabularModel</code>，以及如何使用它获得出色的结果！我们将在下一章中做到这一点。</p>
</section>
<section id="结论" class="level1">
<h1>结论</h1>
<p>对于我们的第一个非计算机视觉应用，我们研究了推荐系统，并看到梯度下降如何从评分历史中学习有关项目的内在因素或偏差。然后，这些因素可以为我们提供有关数据的信息。</p>
<p>我们还在 PyTorch 中构建了我们的第一个模型。在书的下一部分中，我们将做更多这样的工作，但首先，让我们完成对深度学习的其他一般应用的探讨，继续处理表格数据。</p>
</section>
<section id="问卷" class="level1">
<h1>问卷</h1>
<ol type="1">
<li><p>协同过滤解决了什么问题？</p></li>
<li><p>它是如何解决的？</p></li>
<li><p>为什么协同过滤预测模型可能无法成为非常有用的推荐系统？</p></li>
<li><p>协同过滤数据的交叉表表示是什么样的？</p></li>
<li><p>编写代码创建 MovieLens 数据的交叉表表示（您可能需要进行一些网络搜索！）。</p></li>
<li><p>什么是潜在因素？为什么它是“潜在”的？</p></li>
<li><p>什么是点积？使用纯 Python 和列表手动计算点积。</p></li>
<li><p><code>pandas.DataFrame.merge</code>是做什么的？</p></li>
<li><p>什么是嵌入矩阵？</p></li>
<li><p>嵌入和一个独热编码向量矩阵之间的关系是什么？</p></li>
<li><p>如果我们可以使用独热编码向量来做同样的事情，为什么我们需要<code>Embedding</code>？</p></li>
<li><p>在我们开始训练之前，嵌入包含什么内容（假设我们没有使用预训练模型）？</p></li>
<li><p>创建一个类（尽量不要偷看！）并使用它。</p></li>
<li><p><code>x[:,0]</code>返回什么？</p></li>
<li><p>重写<code>DotProduct</code>类（尽量不要偷看！）并用它训练模型。</p></li>
<li><p>在 MovieLens 中使用什么样的损失函数是好的？为什么？</p></li>
<li><p>如果我们在 MovieLens 中使用交叉熵损失会发生什么？我们需要如何更改模型？</p></li>
<li><p>点积模型中偏差的用途是什么？</p></li>
<li><p>权重衰减的另一个名称是什么？</p></li>
<li><p>写出权重衰减的方程（不要偷看！）。</p></li>
<li><p>写出权重衰减的梯度方程。为什么它有助于减少权重？</p></li>
<li><p>为什么减少权重会导致更好的泛化？</p></li>
<li><p>PyTorch 中的<code>argsort</code>是做什么的？</p></li>
<li><p>对电影偏差进行排序是否会得到与按电影平均评分相同的结果？为什么/为什么不？</p></li>
<li><p>如何打印模型中层的名称和详细信息？</p></li>
<li><p>协同过滤中的“自举问题”是什么？</p></li>
<li><p>如何处理新用户的自举问题？对于新电影呢？</p></li>
<li><p>反馈循环如何影响协同过滤系统？</p></li>
<li><p>在协同过滤中使用神经网络时，为什么我们可以为电影和用户使用不同数量的因素？</p></li>
<li><p>为什么在<code>CollabNN</code>模型中有一个<code>nn.Sequential</code>？</p></li>
<li><p>如果我们想要向协同过滤模型添加有关用户和项目的元数据，或者有关日期和时间等信息，应该使用什么样的模型？</p></li>
</ol>
<section id="进一步研究" class="level2">
<h2 class="anchored" data-anchor-id="进一步研究">进一步研究</h2>
<ol type="1">
<li><p>看看<code>Embedding</code>版本的<code>DotProductBias</code>和<code>create_params</code>版本之间的所有差异，并尝试理解为什么需要进行每一项更改。如果不确定，尝试撤销每个更改以查看发生了什么。（注意：甚至在<code>forward</code>中使用的括号类型也已更改！）</p></li>
<li><p>找到另外三个协同过滤正在使用的领域，并在这些领域中确定这种方法的优缺点。</p></li>
<li><p>使用完整的 MovieLens 数据集完成这个笔记本，并将结果与在线基准进行比较。看看你能否提高准确性。在书的网站和 fast.ai 论坛上寻找想法。请注意，完整数据集中有更多列，看看你是否也可以使用这些列（下一章可能会给你一些想法）。</p></li>
<li><p>为 MovieLens 创建一个使用交叉熵损失的模型，并将其与本章中的模型进行比较。</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ssmiro\.ru");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>